{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.gradient.ai/docs/sdk-quickstart"
      ],
      "metadata": {
        "id": "U28aar6Lhrmb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24vNtSU2fEhh",
        "outputId": "97786899-79af-4498-f411-9146f8f45105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradientai\n",
            "  Downloading gradientai-1.8.0-py3-none-any.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aenum>=3.1.11 (from gradientai)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<2.0.0,>=1.10.5 (from gradientai)\n",
            "  Downloading pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0,>=1.10.5->gradientai) (4.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->gradientai) (1.16.0)\n",
            "Installing collected packages: aenum, pydantic, gradientai\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.3\n",
            "    Uninstalling pydantic-2.6.3:\n",
            "      Successfully uninstalled pydantic-2.6.3\n",
            "Successfully installed aenum-3.1.15 gradientai-1.8.0 pydantic-1.10.14\n"
          ]
        }
      ],
      "source": [
        "!pip install gradientai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GRADIENT_WORKSPACE_ID']='0cf8750c-e84c-46a6-af11-96c8b8f83e30_workspace'\n",
        "os.environ['GRADIENT_ACCESS_TOKEN']='B8UZrBC6cK7opx5KWAarsMngkqX8SmeN'"
      ],
      "metadata": {
        "id": "vQJK8xcagb_E"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gradientai import Gradient\n",
        "\n",
        "\n",
        "def main():\n",
        "    gradient = Gradient()\n",
        "\n",
        "    base_model = gradient.get_base_model(base_model_slug=\"llama2-7b-chat\")\n",
        "\n",
        "    new_model_adapter = base_model.create_model_adapter(\n",
        "        name=\"Padmamodel\"\n",
        "    )\n",
        "    print(f\"Created model adapter with id {new_model_adapter.id}\")\n",
        "\n",
        "\n",
        "    sample_query = \"### Instruction: Who is Padmavathi? \\n\\n ### Response:\"\n",
        "    print(f\"Asking: {sample_query}\")\n",
        "    ## Before Finetuning\n",
        "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "    print(f\"Generated(before fine tuning): {completion}\")\n",
        "\n",
        "    samples=[\n",
        "        {\"inputs\":\"### Instruction: Who is Padmvathi? \\n\\n### Response: Padmavathi is a popular mentor and youtuber who uploads videos on Data Science,AI And LLM in his channel Padma Madisetty\"},\n",
        "        {\"inputs\":\"### Instruction: Who is this person named Padmavathi? \\n\\n### Response: Padmavathi Like Data Science And AI And makes videos in youtube and she is also a mentor\"},\n",
        "        {\"inputs\":\"### Instruction: What do you know about Padmavathi? \\n\\n### Response: Padmavathi is a popular creator who specializes in the field of Data Science and her channel name is Padma Madisetty\"},\n",
        "        {\"inputs\":\"### Instruction: Can you tell me about Padmavathi? \\n\\n### Response: Padmavathi is a youtuber,video creator,and a creator who loves Data Science And AI and LLM's\"}\n",
        "    ]\n",
        "\n",
        "    ## Lets define parameters for finetuning\n",
        "    num_epochs=3\n",
        "    count=0\n",
        "    while count<num_epochs:\n",
        "      print(f\"Fine tuning the model with iteration {count + 1}\")\n",
        "      new_model_adapter.fine_tune(samples=samples)\n",
        "      count=count+1\n",
        "\n",
        "    #after fine tuning\n",
        "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "    print(f\"Generated(after fine tuning): {completion}\")\n",
        "    new_model_adapter.delete()\n",
        "    gradient.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKJA8j2phnNU",
        "outputId": "aa6a9c73-62ce-4878-fa02-94e3e11e20fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created model adapter with id 90cca30b-aad7-4024-934c-618257879ef6_model_adapter\n",
            "Asking: ### Instruction: Who is Padmavathi? \n",
            "\n",
            " ### Response:\n",
            "Generated(before fine tuning):  Padmavati is a legendary queen of the Rajput kingdom of Mewar in medieval India. She is a central character in the epic poem \"Padmavat,\" written by Malik Muhammad Jayasi in the 16th century. According to the poem, Padmavati was the wife of Maharana Ratan Singh, the king of Mewar, and was known for her beauty and bravery.\n",
            "\n",
            "The story of Padmavati is\n",
            "Fine tuning the model with iteration 1\n",
            "Fine tuning the model with iteration 2\n",
            "Fine tuning the model with iteration 3\n",
            "Generated(after fine tuning):  Padmavathi is a popular YouTuber, video creator, and AI language model developer who specializes in the field of Data Science,AI, and LLM's. She is the creator of the channel Padma Madisetty, where she uploads videos on Data Science,AI,LLM's, and other related topics. She is also the creator of the popular blog \" Padma Madisetty\" where she shares her knowledge on\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "r_I2Ti6ihqPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gradientai import Gradient\n",
        "\n",
        "def main():\n",
        "    gradient = Gradient()\n",
        "\n",
        "    base_model = gradient.get_base_model(base_model_slug=\"nous-hermes2\")\n",
        "\n",
        "    new_model_adapter = base_model.create_model_adapter(\n",
        "        name=\"my test model adapter\"\n",
        "    )\n",
        "    print(f\"Created model adapter with id {new_model_adapter.id}\")\n",
        "\n",
        "    new_model_adapter.fine_tune(samples=[{\"inputs\": \"princess, dragon, castle\"}])\n",
        "    sample_query = \"what is the largest animal?\"\n",
        "    print(f\"Asking: {sample_query}\")\n",
        "\n",
        "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "    print(f\"Generated: {completion}\")\n",
        "\n",
        "    new_model_adapter.delete()\n",
        "    gradient.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrOShscXguY7",
        "outputId": "7564761c-dc27-487e-a499-093eec2dc2b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created model adapter with id 714360be-6349-4ff6-8e59-b2e8285bd3a9_model_adapter\n",
            "Asking: what is the largest animal?\n",
            "Generated:  The largest animal is the blue whale. It can grow to be over 100 feet long and weighing upwards of 200 tons.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uOtOmCsjkIQz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}